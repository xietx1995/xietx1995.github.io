<!DOCTYPE html>
<html lang=" en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>机器学习笔记 - 梯度下降优化方法总结 | Tianxin’s Blog</title>
<meta name="generator" content="Jekyll v4.2.0">
<meta property="og:title" content="机器学习笔记 - 梯度下降优化方法总结">
<meta name="author" content="Tianxin Xie">
<meta property="og:locale" content="en_US">
<meta name="description" content="在机器学习实践中，我们会用许多手段来提升梯度下降算法的性能。本文主要参考一篇 review，总结了在模型训练过程中常用的优化方法。本文的主要内容翻译自该篇 review，做了增删改，并加上了部分自己的理解，以及额外的图示、视频和阅读材料。">
<meta property="og:description" content="在机器学习实践中，我们会用许多手段来提升梯度下降算法的性能。本文主要参考一篇 review，总结了在模型训练过程中常用的优化方法。本文的主要内容翻译自该篇 review，做了增删改，并加上了部分自己的理解，以及额外的图示、视频和阅读材料。">
<link rel="canonical" href="https://xietx1995.github.io/2021/optimization">
<meta property="og:url" content="https://xietx1995.github.io/2021/optimization">
<meta property="og:site_name" content="Tianxin’s Blog">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2021-07-04T00:00:00+08:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="机器学习笔记 - 梯度下降优化方法总结">
<script type="application/ld+json">
{"description":"在机器学习实践中，我们会用许多手段来提升梯度下降算法的性能。本文主要参考一篇 review，总结了在模型训练过程中常用的优化方法。本文的主要内容翻译自该篇 review，做了增删改，并加上了部分自己的理解，以及额外的图示、视频和阅读材料。","headline":"机器学习笔记 - 梯度下降优化方法总结","dateModified":"2021-07-04T00:00:00+08:00","datePublished":"2021-07-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://xietx1995.github.io/2021/optimization"},"url":"https://xietx1995.github.io/2021/optimization","author":{"@type":"Person","name":"Tianxin Xie"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="shortcut icon" href="/assets/images/favicon.png">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <script src="/assets/js/main.js"></script><link type="application/atom+xml" rel="alternate" href="https://xietx1995.github.io/feed.xml" title="Tianxin's Blog">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js"></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>



























































































































<header class="site-header " role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/">
  <img class="site-favicon" title="Tianxin's Blog" src="/assets/images/favicon.png" onerror="this.style.display='none'">
</a></span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">
            
            <a class="page-link" href="/">HOME</a><a class="page-link" href="/categories.html">CATEGORIES</a><a class="page-link" href="/archives.html">ARCHIVES</a><a class="page-link" href="/tags.html">TAGS</a><a class="page-link" href="/about.html">ABOUT</a>

            <!--<a class="page-link" href="/about.html">ABOUT</a><a class="page-link" href="/archives.html">ARCHIVES</a><a class="page-link" href="/categories.html">CATEGORIES</a><a class="page-link" href="/">HOME</a><a class="page-link" href="/tags.html">TAGS</a>-->




</div>
        </nav>
</div>
  </div>
</header>

<script>
  (function() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  })();
</script>
















































































































































<script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<!--<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('auto' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
-->

  <main class="page-content" aria-label="Content">
    <div class="wrapper">
      <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">机器学习笔记 - 梯度下降优化方法总结</h1>
  <h2 class="post-subtitle"></h2>

  <p class="post-meta">
    <time class="dt-published" datetime="2021-07-04T00:00:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Jul 04, 2021
    </time>

    
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 13 mins</span>
  </p>
<div class="post-tags"><a class="post-tag" href="/tags.html#ai">#ai</a></div></header>
<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <p>在机器学习实践中，我们会用许多手段来提升梯度下降算法的性能。本文主要参考一篇 <a href="https://ruder.io/optimizing-gradient-descent/">review</a>，总结了在模型训练过程中常用的优化方法。本文的主要内容翻译自该篇 <a href="https://ruder.io/optimizing-gradient-descent/">review</a>，做了增删改，并加上了部分自己的理解，以及额外的图示、视频和阅读材料。</p>

<blockquote>
  <p>This blog post aims at providing you with intuitions towards the behaviour of different algorithms for optimizing gradient descent that will help you put them to use. We are first going to look at the different variants of gradient descent. We will then briefly summarize challenges during training. Subsequently, we will introduce the most common optimization algorithms by showing their motivation to resolve these challenges and how this leads to the derivation of their update rules. We will also take a short look at algorithms and architectures to optimize gradient descent in a parallel and distributed setting. Finally, we will consider additional strategies that are helpful for optimizing gradient descent.</p>

  <p>​                                                                                              –  “An overview of gradient descent optimization algorithms”</p>
</blockquote>

<h2 id="1-梯度下降的变种">1 梯度下降的变种</h2>

<p>这里介绍三种梯度下降的方法：</p>

<ul>
  <li>Batch Gradient Descent</li>
  <li>Stochastic Gradient Descent</li>
  <li>Mini-batch gradient descent</li>
</ul>

<p>这三种梯度下降方法的唯一区别就是每个 step 使用的数据量不同。</p>

<h3 id="11-batch-gradient-descent">1.1 Batch Gradient Descent</h3>

<p>这是最原始的梯度下降方法，翻译过来就是”批量梯度下降“，每个 step 使用整个训练集。</p>

\[\theta = \theta - \eta\cdot\triangledown_{\theta} J(\theta)\]

<p>这个方法有三个问题：</p>

<ul>
  <li>每个 step 都需要对整个训练集计算梯度，速度很慢；</li>
  <li>现在的数据集都较大，内存装不下整个训练集；</li>
  <li>不能进行 online training，例如已经部署好的一个模型，不能用新样本调整模型。</li>
</ul>

<p>Batch Gradient Descent 的代码形式通常如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_epochs</span><span class="p">):</span>
   <span class="n">params_grad</span> <span class="o">=</span> <span class="n">evaluate_gradient</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
   <span class="n">params</span> <span class="o">=</span> <span class="n">params</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">params_grad</span>
</code></pre></div></div>

<p>首先计算参数关于整个数据集的梯度，然后再用梯度乘以学习率来更新模型参数。如果 loss 函数是凸面，批量梯度下降能保证找到全局最优的参数，否则找到的可能是局部最优值。</p>

<h3 id="12-stochastic-gradient-descent">1.2 Stochastic Gradient Descent</h3>

<p>SGD 也称为随机梯度下降，和 BGD 是两个极端，BGD 一个 step 使用整个训练集，SGD 一次只用一个训练样本 $(x^{(i)}, y^{(i)})$ ：</p>

\[\theta = \theta - \eta \cdot \nabla_\theta J( \theta; x^{(i)}; y^{(i)})\]

<p>SGD有两个好处：</p>

<ul>
  <li>速度快，每次只用一个样本；</li>
  <li>可以进行 online training。</li>
</ul>

<p>SGD 也有一个比较大的缺点，就是在训练过程中，loss 函数的波动很大，导致较高的 variance：</p>

<p><img src="/assets/images/post_imgs/MLNotes_Optimization.assets/sgd_fluctuation.png" alt="sgd_fluctuation"></p>

<p>很容易就能想象，SGD 的这种波动使得模型容易越过最优点。但是实验表明，如果在梯度下降的过程中逐渐减小学习率，最终几乎和 BGD 一样能够到达最优点 (convex loss) 或者局部最优点 (non-convex loss)。伪代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_epochs</span><span class="p">):</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">params_grad</span> <span class="o">=</span> <span class="n">evaluate_gradient</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">params</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">params_grad</span>
</code></pre></div></div>

<p>每个 epoch 都对数据集进行了 <a href="https://stats.stackexchange.com/a/311318">shuffle</a>，然后每次使用一个样本更新参数。</p>

<h3 id="13-mini-batch-gradient-descent">1.3 Mini-batch Gradient Descent</h3>

<p>中文称其为小批量梯度下降，我们就简称 MBGD 吧。</p>

\[\theta = \theta - \eta \cdot \nabla_\theta J( \theta; x^{(i:i+n)}; y^{(i:i+n)})\]

<p>MBGD 每个 step 只使用训练集的一小部分，根据数据集大小、设备性能、内存、显存容量等，一般取 32， 64， 128， 256， 512 等。它综合了 BGD 和 SGD 的优点：</p>

<ul>
  <li>loss 和参数不会有很大的波动；</li>
  <li>训练速度快 (目前的训练框架能高效地计算梯度)；</li>
  <li>可以 online training (只需集齐一个batch就可以)。</li>
</ul>

<p>MBGD 也能达最优点 (convex loss) 或者局部最优点 (non-convex loss)。伪代码：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_epochs</span><span class="p">):</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">get_batches</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span> <span class="c1"># 每个step取50个样本
</span>        <span class="n">params_grad</span> <span class="o">=</span> <span class="n">evaluate_gradient</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">params</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">params_grad</span>
</code></pre></div></div>

<h2 id="2-问题挑战">2 问题挑战</h2>

<p>Mini-batch gradient descent 虽然一定程度上克服了 BGD 和 SGD 的一些缺点，但是还面临如下问题：</p>

<ul>
  <li>难以选择合适的学习率，过小导致训练速度慢，过大导致 loss 波动甚至发散；</li>
  <li>可以对学习率动态调整，如训练过程中逐渐减小学习率，但是如何减小，减小多少也是需要提前定义的。而数据集的不同可能需要不同的调整策略；</li>
  <li>同一个学习率对不同参数的效果可能大相径庭，如果数据集各个特征的频率 (出现次数) 差异较大，我们可能不想对它们采取同样的更新策略。例如频率较小的特征，可能需要较大的学习率；</li>
  <li>一个较大的问题是目前很多模型 (使用神经网络) 都是 non-convex 的，所以模型很可能被训练到一个局部最优点。另外，模型如果落入<a href="https://en.wikipedia.org/wiki/Saddle_point">鞍点</a> (saddle points)，就很难继续训练，因为各个方向的梯度都几乎为 0。</li>
</ul>

<h2 id="3-梯度下降优化算法">3 梯度下降优化算法</h2>

<p>接下来介绍实践中常用于应对上述问题的方法 (不包括对高维数据计算复杂度较大的方法，如二阶牛顿法)。</p>

<h3 id="31-momentum">3.1 Momentum</h3>

<p>Momentum 又称为动量法，其思路很简单。想象一个小球从高处滚落，小球的速度是矢量，可以分解为各个方向的分量，一直下降的方向的速度分量会越来越大，而有下降又有上升的方向，速度分量会缓慢增加、甚至减少。从下面的示意图中可以看到 momentum 方法速度非常快。</p>

<p><img src="/assets/images/post_imgs/MLNotes_Optimization.assets/sgd_comparison.gif" alt="GitHub - ilguyi/optimizers.numpy"></p>

<p>在 SGD with moment 方法中，我们维持一个梯度累积向量 $v$ (类比小球速度矢量)，公式如下：</p>

\[\begin{align}
\begin{split}
v_t &amp;= \gamma v_{t-1} + \eta \nabla_\theta J( \theta) \\
\theta &amp;= \theta - v_t
\end{split}
\end{align}\]

<p>有些文章中的符号是相反的，也是正确的：</p>

\[\begin{align}
\begin{split}
v_t &amp;= \gamma v_{t-1} - \eta \nabla_\theta J( \theta) \\
\theta &amp;= \theta + v_t
\end{split}
\end{align}\]

<p>$\gamma$ 是 momentum 的权重，一般取 0.9。</p>

<h3 id="32-nesterov-accelerated-gradient">3.2 ​Nesterov Accelerated Gradient</h3>

<p>Nesterov Accelerated Gradient(NAG) 对 momentum 做了一点改进：</p>

\[\begin{align}
\begin{split}
v_t &amp;= \gamma v_{t-1} + \eta \nabla_\theta J(\theta-\gamma v_{t-1}) \\
\theta &amp;= \theta - v_t
\end{split}
\end{align}\]

<p>NAG 先往前迈一步，即 $\theta-\gamma v_{t-1}$，然后计算梯度，接着用计算出的梯度修正当前的梯度累积量。而 momentum 是先在当前位置计算梯度，然后再跳一大步更新位置。</p>

<p><img src="/assets/images/post_imgs/MLNotes_Optimization.assets/nesterov.png" alt="nesterov"></p>

<p>上图中，绿色为最佳路线，蓝色为 momentum 路线 (先计算梯度，累计，再跳一大步)，褐色 + 红色为 NAG 路线 (先跳一大步，再计算梯度，修正)。</p>

<h3 id="33-adagrad">3.3 AdaGrad</h3>

<p>‎AdaGrad‎ ‎可使学习速率适应参数。它对样本中出现频率较高的特征对应的参数执行较小的更新，对频率较低的特征对应的参数执行较大的更新。其更新规则如下：</p>

<ol>
  <li>
    <p>在步骤 t，用 $s_t$ 保存各个参数每个 step 的梯度的平方和：</p>

\[s_t = s_{t-1} + g_t\odot g_t\]

    <p>这里 $\odot$ 是元素对应相乘，即计算梯度向量每个元素的平方。可以看出，如果某个参数下降很快，那么 $s_t$ 对应分量的累计就越大。</p>
  </li>
  <li>
    <p>更新参数：</p>

\[\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{s_t + \epsilon}} \odot g_t\]

    <p>因为下降越快的参数 $s_t$ 中的分量越大，那么 $\frac{\eta}{\sqrt{s_t + \epsilon}}$ 就会越小，即学习速率就更小，反之下降慢的参数，对应的学习速率就高一点。</p>
  </li>
</ol>

<p>这里的 $\epsilon$ 是一个很小的正值，防止计算过程中除零 (通常取 $1e-8$ 级别的数)。另外一点是不开方的话，效果会很差。</p>

<p>AdaGrad 的好处是不需要手动调整学习率。但有个缺点：由于累积梯度向量 $s_t$ 的元素每个步骤新增项都是正数 (该分量梯度的平方)，因此在训练期间累积的总和不断增加， $\frac{\eta}{\sqrt{s_t + \epsilon}}$ 不断减小，导致学习率缩小并变得极小 (学习率消失)‎。</p>

<p>AdaGrad 于 2011 年被提出，由于学习率消失的问题，已经基本无人采用，具体细节可以阅读论文 ”Duchi, J., Hazan, E., &amp; Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. Journal of Machine Learning Research, 12, 2121–2159.“。</p>

<h3 id="34-adadelta">3.4 AdaDelta</h3>

<p>AdaDelta 是 ‎AdaGrad‎ 的改良版本，目的是解决梯度平方累计导致的学习速率极小(消失)的问题。其思路很简单，维护一个累积窗口，而不是累积每一步的梯度。具体参考：<a href="https://paperswithcode.com/method/adadelta">AdaDelta Explained</a>。</p>

<p>四种方法比较：</p>

<p><img src="/assets/images/post_imgs/MLNotes_Optimization.assets/sgd_adagrad.png" alt="sgd_adagrad"></p>

<h3 id="35-rmsprop">3.5 RMSProp</h3>

<p>RMSprop 未经论文发表，是一种适应性的学习速率调整方法，该方法由 Geoff Hinton 在他的 Coursera <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">课程讲义</a>中提出，和 AdaDelta 的目的相同，也是为了解决 AdaGrad 学习率消失问题。</p>

<p>RMSProp 的更新规则如下：</p>

<ol>
  <li>
    <p>在步骤 t，计算：</p>

\[s_t = \gamma s_{t-1} + (1-\gamma)g_t\odot g_t\]
  </li>
  <li>
    <p>更新参数：</p>

\[\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{s_t + \epsilon}} \odot g_t\]
  </li>
</ol>

<p>我们把第一步计算 $s_t$ 的公式展开：</p>

\[\begin{split}\begin{aligned}
\mathbf{s}_t &amp; = (1 - \gamma) \mathbf{g}_t^2 + \gamma \mathbf{s}_{t-1} \\
&amp; = (1 - \gamma) \left(\mathbf{g}_t^2 + \gamma \mathbf{g}_{t-1}^2 + \gamma^2 \mathbf{g}_{t-2} + \ldots, \right).
\end{aligned}\end{split}\]

<p>我们知道 $1 + \gamma + \gamma^2 + \ldots = \frac{1}{1-\gamma}$，即 $s_t$ 是之前步骤累积梯度的期望值，因为 $\gamma &lt; 1$，越早的梯度累计对当前的影响越小，很多步之前的梯度累计甚至可以忽略不计，故不会出现 $s_t$ 无限制增长，导致学习率消失的问题。我们可以使用 $\gamma$ 来控制 $s_t$ 对历史梯度的累积范围。下面的图片是不同 $\gamma$ 取值对应的历史梯度累计的权重：</p>

<p><img src="/assets/images/post_imgs/MLNotes_Optimization.assets/rmsprop_gamma.png" alt="rmsprop_gamma"></p>

<p>从上图可以看出，取值越大，$s_t$ 越”关注“历史积累的梯度。40 步之前的积累，虽然在解析式中不为 0，但在内存中数值上已经为 0。</p>

<h3 id="36-adam">3.6 Adam</h3>

<p>Adam 是 RMSProp 和 Momentum 的结合。</p>

\[\begin{split}\begin{aligned}
    \mathbf{v}_t &amp; \leftarrow \beta_1 \mathbf{v}_{t-1} + (1 - \beta_1) \mathbf{g}_t \\
    \mathbf{s}_t &amp; \leftarrow \beta_2 \mathbf{s}_{t-1} + (1 - \beta_2) \mathbf{g}_t \odot \mathbf{g}_t
\end{aligned}\end{split}\]

<p>第一行公式即 Momentum，通常 $\beta_1 = 0.9$。第二行即 RMSProp，通常 $\beta_2 = 0.999$。</p>

<p>在刚开始时我们把 $\mathbf{v}_t$ 和 $\mathbf{s}_t$ 设为 0，即 $\mathbf{v}_0 = \mathbf{s}_0 = 0$，那么有 $\mathbf{v}_1 = 0.1 \mathbf{g}_1$，而不是真正的梯度值。$\mathbf{s}_1$ 也有同样的问题。故越早的时间步，偏差越大，因此我们要修正偏差。</p>

<p>在时间步 t 我们得到</p>

\[\boldsymbol{v}_t = (1-\beta_1) \sum_{i=1}^{t} \beta_1^{t-i} \boldsymbol{g}_i\]

<p>(上面第一个式子展开)，将过去各时间步小批量随机梯度的权值相加，得到</p>

\[(1-\beta_1) \sum_{i=1}^t \beta_1^{t-i} = 1 - \beta_1^t\]

<p>需要注意的是，当 t 较小时，过去各时间步小批量随机梯度权值之和会较小。例如，当 $\beta_1 = 0.9$ 时，$\mathbf{v}_1 = 0.1 \mathbf{g}_1$，所有权值之和为 0.1。为了消除这样的影响，对于任意时间步 t，我们可以将 $\mathbf{v}_t$ 再除以$1 - \beta_1^t$，从而使过去各时间步小批量随机梯度权值之和为1。这也叫作偏差修正。在Adam算法中，我们对变量均 $\mathbf{v}_t$ 和 $\mathbf{s}_t$ 作偏差修正：</p>

\[\hat{\boldsymbol{v}}_t \leftarrow \frac{\boldsymbol{v}_t}{1 - \beta_1^t},\]

\[\hat{\boldsymbol{s}}_t \leftarrow \frac{\boldsymbol{s}_t}{1 - \beta_2^t}.\]

<p>最后进行更新：</p>

\[\boldsymbol{x}_t \leftarrow
\boldsymbol{x}_t - \frac{\eta \hat{\boldsymbol{v}}_t}{\sqrt{\hat{\boldsymbol{s}}_t} + \epsilon},\]

<p>其中 $\eta$ 是学习率，$\epsilon$ 是为了维持数值稳定性而添加的常数，如 $10^{−8}$。和 AdaGrad 算法、RMSProp 算法以及AdaDelta 算法一样，目标函数自变量中每个元素都分别拥有自己的学习率。</p>

<hr>

<p>👍强烈推荐以下视频，讲了Momentum, Adagrad, RMSProp, Adam 的原理和演进关系：</p>

<ul>
  <li>B站(无字幕)：<a href="https://www.bilibili.com/video/BV134411q793?share_source=copy_web">https://www.bilibili.com/video/BV134411q793?share_source=copy_web</a>
</li>
  <li>油管(有自动生成字幕)：<a href="https://www.youtube.com/watch?v=gmwxUy7NYpA">L26/1 Momentum, Adagrad, RMSProp, Adam - YouTube</a>
</li>
</ul>

<hr>

<h3 id="37-其他优化器">3.7 其他优化器</h3>

<p>该篇 <a href="https://ruder.io/optimizing-gradient-descent/">review</a> 还讲解了其他优化器，由于在实践中，除非是专门研究优化器，基本不会使用它们，所以本文节约时间点到为止。这些优化器均在 <a href="https://paperswithcode.com/methods/category/stochastic-optimization">An Overview of Stochastic Optimization</a> 列出，感兴趣可以查看。下面是各种优化器在鞍点上的表现：</p>

<p><img src="/assets/images/post_imgs/MLNotes_Optimization.assets/saddle_point_evaluation_optimizers.gif" alt="saddle_point_evaluation_optimizers"></p>

<h3 id="38-选用哪个优化器">3.8 选用哪个优化器？</h3>

<p>该篇 <a href="https://ruder.io/optimizing-gradient-descent/">review</a> 中写道：</p>

<blockquote>
  <p>So, which optimizer should you now use? If your input data is sparse, then you likely achieve the best results using one of the adaptive learning-rate methods. An additional benefit is that you won’t need to tune the learning rate but likely achieve the best results with the default value.</p>

  <p>In summary, RMSprop is an extension of Adagrad that deals with its radically diminishing learning rates. It is identical to Adadelta, except that Adadelta uses the RMS of parameter updates in the numinator update rule. Adam, finally, adds bias-correction and momentum to RMSprop. Insofar, RMSprop, Adadelta, and Adam are very similar algorithms that do well in similar circumstances. Kingma et al. [<a href="https://ruder.io/optimizing-gradient-descent/index.html#fn14">14:1]</a> show that its bias-correction helps Adam slightly outperform RMSprop towards the end of optimization as gradients become sparser. Insofar, ==Adam might be the best overall choice==.</p>

  <p>Interestingly, many recent papers use vanilla SGD without momentum and a simple learning rate annealing schedule. As has been shown, SGD usually achieves to find a minimum, but it might take significantly longer than with some of the optimizers, is much more reliant on a robust initialization and annealing schedule, and may get stuck in saddle points rather than local minima. Consequently, if you care about fast convergence and train a deep or complex neural network, you should choose one of the adaptive learning rate methods.</p>

  <p>​                                                                                                  –  “An overview of gradient descent optimization algorithms”</p>
</blockquote>

<p>大多数情况用 Adam 就对了！</p>

<h2 id="4-其他优化策略">4 其他优化策略</h2>

<p>该篇 <a href="https://ruder.io/optimizing-gradient-descent/index.html#additionalstrategiesforoptimizingsgd">review</a> 中提到的关于 SGD 的其他优化策略包括：</p>

<ul>
  <li><a href="https://stats.stackexchange.com/questions/245502/why-should-we-shuffle-data-while-training-a-neural-network">Shuffling</a></li>
  <li><a href="https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/">Batch Normalization</a></li>
  <li><a href="https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/">Early Stopping</a></li>
  <li><a href="https://arxiv.org/abs/1511.06807">Gradient Noise</a></li>
</ul>

<p>Shuffling 和 Batch Normalization 是实践中常用的。</p>

<h2 id="推荐阅读">推荐阅读</h2>

<ol>
  <li><a href="https://ruder.io/optimizing-gradient-descent/index.html">An overview of gradient descent optimization algorithms (ruder.io)</a></li>
  <li><a href="https://paperswithcode.com/methods/category/stochastic-optimization">An Overview of Stochastic Optimization</a></li>
  <li><a href="https://d2l.ai/chapter_optimization/index.html">11. Optimization Algorithms — Dive into Deep Learning 0.16.6 documentation (d2l.ai)</a></li>
  <li><a href="https://distill.pub/2017/momentum/">Why Momentum Really Works (distill.pub)</a></li>
  <li><a href="https://stats.stackexchange.com/questions/245502/why-should-we-shuffle-data-while-training-a-neural-network">Why should we shuffle data while training a neural network?</a></li>
  <li><a href="https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/">A Gentle Introduction to Batch Normalization for Deep Neural Networks (machinelearningmastery.com)</a></li>
  <li><a href="https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/">A Gentle Introduction to Early Stopping to Avoid Overtraining Neural Networks (machinelearningmastery.com)</a></li>
</ol>

<h2 id="参考文献">参考文献</h2>

<ol>
  <li>H. Robinds and S. Monro, “A stochastic approximation method,” Annals of Mathematical Statistics, vol. 22, pp. 400–407, 1951. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref1">↩︎</a>
</li>
  <li>Darken, C., Chang, J., &amp; Moody, J. (1992). Learning rate schedules for faster stochastic gradient search. Neural Networks for Signal Processing II Proceedings of the 1992 IEEE Workshop, (September), 1–11. <a href="https://hub.pubmedplus.com/10.1109/NNSP.1992.253713">http://doi.org/10.1109/NNSP.1992.253713</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref2">↩︎</a>
</li>
  <li>Dauphin, Y., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., &amp; Bengio, Y. (2014). Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. arXiv, 1–14. Retrieved from <a href="https://arxiv.org/abs/1406.2572">http://arxiv.org/abs/1406.2572</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref3">↩︎</a>
</li>
  <li>Sutton, R. S. (1986). Two problems with backpropagation and other steepest-descent learning procedures for networks. Proc. 8th Annual Conf. Cognitive Science Society. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref4">↩︎</a>
</li>
  <li>Qian, N. (1999). On the momentum term in gradient descent learning algorithms. Neural Networks : The Official Journal of the International Neural Network Society, 12(1), 145–151. <a href="https://hub.pubmedplus.com/10.1016/S0893-6080(98)00116-6">http://doi.org/10.1016/S0893-6080(98)00116-6</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref5">↩︎</a>
</li>
  <li>Nesterov, Y. (1983). A method for unconstrained convex minimization problem with the rate of convergence o(1/k2). Doklady ANSSSR (translated as Soviet.Math.Docl.), vol. 269, pp. 543– 547. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref6">↩︎</a>
</li>
  <li>Bengio, Y., Boulanger-Lewandowski, N., &amp; Pascanu, R. (2012). Advances in Optimizing Recurrent Networks. Retrieved from <a href="https://arxiv.org/abs/1212.0901">http://arxiv.org/abs/1212.0901</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref7">↩︎</a>
</li>
  <li>Sutskever, I. (2013). Training Recurrent neural Networks. PhD Thesis. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref8">↩︎</a>
</li>
  <li>Duchi, J., Hazan, E., &amp; Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. Journal of Machine Learning Research, 12, 2121–2159. Retrieved from <a href="http://jmlr.org/papers/v12/duchi11a.html">http://jmlr.org/papers/v12/duchi11a.html</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref9">↩︎</a>
</li>
  <li>Dean, J., Corrado, G. S., Monga, R., Chen, K., Devin, M., Le, Q. V, … Ng, A. Y. (2012). Large Scale Distributed Deep Networks. NIPS 2012: Neural Information Processing Systems, 1–11. <a href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf">http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref10">↩︎</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref10:1">↩︎</a>
</li>
  <li>Pennington, J., Socher, R., &amp; Manning, C. D. (2014). Glove: Global Vectors for Word Representation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, 1532–1543. <a href="https://hub.pubmedplus.com/10.3115/v1/D14-1162">http://doi.org/10.3115/v1/D14-1162</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref11">↩︎</a>
</li>
  <li>Duchi et al. [3] give this matrix as an alternative to the <em>full</em> matrix containing the outer products of all previous gradients, as the computation of the matrix square root is infeasible even for a moderate number of parameters dd. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref12">↩︎</a>
</li>
  <li>Zeiler, M. D. (2012). ADADELTA: An Adaptive Learning Rate Method. Retrieved from <a href="https://arxiv.org/abs/1212.5701">http://arxiv.org/abs/1212.5701</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref13">↩︎</a>
</li>
  <li>Kingma, D. P., &amp; Ba, J. L. (2015). Adam: a Method for Stochastic Optimization. International Conference on Learning Representations, 1–13. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref14">↩︎</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref14:1">↩︎</a>
</li>
  <li>Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., &amp; Hochreiter, S. (2017). GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. In Advances in Neural Information Processing Systems 30 (NIPS 2017). <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref15">↩︎</a>
</li>
  <li>Dozat, T. (2016). Incorporating Nesterov Momentum into Adam. ICLR Workshop, (1), 2013–2016. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref16">↩︎</a>
</li>
  <li>Huang, G., Liu, Z., Weinberger, K. Q., &amp; van der Maaten, L. (2017). Densely Connected Convolutional Networks. In Proceedings of CVPR 2017. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref17">↩︎</a>
</li>
  <li>Johnson, M., Schuster, M., Le, Q. V, Krikun, M., Wu, Y., Chen, Z., … Dean, J. (2016). Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation. arXiv Preprint arXiv:1611.0455. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref18">↩︎</a>
</li>
  <li>Reddi, Sashank J., Kale, Satyen, &amp; Kumar, Sanjiv. On the Convergence of Adam and Beyond. Proceedings of ICLR 2018. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref19">↩︎</a>
</li>
  <li>Loshchilov, I., &amp; Hutter, F. (2019). Decoupled Weight Decay Regularization. In Proceedings of ICLR 2019. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref20">↩︎</a>
</li>
  <li>Ma, J., &amp; Yarats, D. (2019). Quasi-hyperbolic momentum and Adam for deep learning. In Proceedings of ICLR 2019. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref21">↩︎</a>
</li>
  <li>Lucas, J., Sun, S., Zemel, R., &amp; Grosse, R. (2019). Aggregated Momentum: Stability Through Passive Damping. In Proceedings of ICLR 2019. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref22">↩︎</a>
</li>
  <li>Niu, F., Recht, B., Christopher, R., &amp; Wright, S. J. (2011). Hogwild! : A Lock-Free Approach to Parallelizing Stochastic Gradient Descent, 1–22. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref23">↩︎</a>
</li>
  <li>Mcmahan, H. B., &amp; Streeter, M. (2014). Delay-Tolerant Algorithms for Asynchronous Distributed Online Learning. Advances in Neural Information Processing Systems (Proceedings of NIPS), 1–9. Retrieved from <a href="http://papers.nips.cc/paper/5242-delay-tolerant-algorithms-for-asynchronous-distributed-online-learning.pdf">http://papers.nips.cc/paper/5242-delay-tolerant-algorithms-for-asynchronous-distributed-online-learning.pdf</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref24">↩︎</a>
</li>
  <li>Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., … Zheng, X. (2015). TensorFlow : Large-Scale Machine Learning on Heterogeneous Distributed Systems. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref25">↩︎</a>
</li>
  <li>Zhang, S., Choromanska, A., &amp; LeCun, Y. (2015). Deep learning with Elastic Averaging SGD. Neural Information Processing Systems Conference (NIPS 2015), 1–24. Retrieved from <a href="https://arxiv.org/abs/1412.6651">http://arxiv.org/abs/1412.6651</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref26">↩︎</a>
</li>
  <li>LeCun, Y., Bottou, L., Orr, G. B., &amp; Müller, K. R. (1998). Efficient BackProp. Neural Networks: Tricks of the Trade, 1524, 9–50. <a href="https://hub.pubmedplus.com/10.1007/3-540-49430-8_2">http://doi.org/10.1007/3-540-49430-8_2</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref27">↩︎</a>
</li>
  <li>Bengio, Y., Louradour, J., Collobert, R., &amp; Weston, J. (2009). Curriculum learning. Proceedings of the 26th Annual International Conference on Machine Learning, 41–48. <a href="https://hub.pubmedplus.com/10.1145/1553374.1553380">http://doi.org/10.1145/1553374.1553380</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref28">↩︎</a>
</li>
  <li>Zaremba, W., &amp; Sutskever, I. (2014). Learning to Execute, 1–25. Retrieved from <a href="https://arxiv.org/abs/1410.4615">http://arxiv.org/abs/1410.4615</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref29">↩︎</a>
</li>
  <li>Ioffe, S., &amp; Szegedy, C. (2015). Batch Normalization : Accelerating Deep Network Training by Reducing Internal Covariate Shift. arXiv Preprint arXiv:1502.03167v3. <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref30">↩︎</a>
</li>
  <li>Neelakantan, A., Vilnis, L., Le, Q. V., Sutskever, I., Kaiser, L., Kurach, K., &amp; Martens, J. (2015). Adding Gradient Noise Improves Learning for Very Deep Networks, 1–11. Retrieved from <a href="https://arxiv.org/abs/1511.06807">http://arxiv.org/abs/1511.06807</a> <a href="https://ruder.io/optimizing-gradient-descent/index.html#fnref31">↩︎</a>
</li>
</ol>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/2021/activations" title="机器学习笔记 - 激活函数总结">机器学习笔记 - 激活函数总结</a><a class="next" href="/2021/cs231n_summary" title="CS231n学习总结">CS231n学习总结</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li><a class="post-link" href="/2021/activations" title="CS231n学习总结">机器学习笔记 - 激活函数总结</a></li>
<li><a class="post-link" href="/2021/optimization" title="CS231n学习总结">机器学习笔记 - 梯度下降优化方法总结</a></li>
<li><a class="post-link" href="/2021/cs231n_summary" title="CS231n学习总结">CS231n学习总结</a></li>
<li><a class="post-link" href="/2021/softmax" title="CS231n学习总结">机器学习笔记 - Softmax</a></li>
</ul>
    </div>
<div class="post-comments">  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'https://xietx1995.github.io/2021/optimization';
      this.page.identifier = 'https://xietx1995.github.io/2021/optimization';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://xietx1995.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
</div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

    </div>
  </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
      <div>Copyright © 2021 @Tianxin Xie</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="http://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
    </div>
  </div>
</footer>
<script src="/assets/js/vanilla-back-to-top.min.js"></script>
  <script>addBackToTop({
      diameter: 56,
      backgroundColor: '#ff5100',
      textColor: '#fff'
    })</script>

</body>

</html>
